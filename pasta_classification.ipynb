{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy6at15hsZouqsHMzQTiir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomhyhan/noodles/blob/main/pasta_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "koRTiaedWIZg"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R_0RIvAmdQ6_",
        "outputId": "c626535d-87f5-47ac-d949-e5c66b6be567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D_qi0FsOdU4O",
        "outputId": "cd131ce3-af30-4511-e7a2-40c29fd75008"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/noodles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "token = userdata.get('token')\n",
        "username = userdata.get('username')\n",
        "repo_name = \"noodles\""
      ],
      "metadata": {
        "id": "AoEzSbksdZc_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tomhyhan/{repo_name}.git\n",
        "%cd {repo_name}\n",
        "!git pull\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Qp5GmDHYdx-f",
        "outputId": "4e1c01ef-1f42-4d64-fd00-fcf5444b9a5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/noodles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model.utils import test_colab\n",
        "test_colab()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7VNUEnJld36I",
        "outputId": "dd458e10-0e17-4090-ca70-a9c9374278eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Colab! from Noodles ha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GG5zmBhQiSRI",
        "outputId": "50e55e93-e35d-48f1-9f5a-ea59df9db38d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets, imagehash\n",
            "Successfully installed PyWavelets-1.7.0 imagehash-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "\n",
        "from config.config_manager import ConfigManager\n",
        "from collections import Counter\n",
        "from model.data_model import PastaData\n",
        "from model.train import trainer, create_model\n",
        "from model.utils import reset_seed\n",
        "from model.data import CLASS_ENCODER\n",
        "from model.viz import class_imblance"
      ],
      "metadata": {
        "id": "hGm4lDMygOyt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_manager = ConfigManager(\"./config/config.yml\")\n",
        "\n",
        "SEED = config_manager.config.seed"
      ],
      "metadata": {
        "id": "8duPbwRyiqLr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seed(SEED)"
      ],
      "metadata": {
        "id": "17_od-fOiIeZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./pasta_data.csv\")\n",
        "image_paths, labels = data[\"img_path\"], data[\"label\"]\n",
        "\n",
        "X, test_data, y, test_label = train_test_split(image_paths.values, labels.values, train_size=0.9, random_state=SEED, shuffle=True, stratify=labels)"
      ],
      "metadata": {
        "id": "1IOZHmWAf7pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "models = ['swin']\n",
        "for model_name in models:\n",
        "    for k_id, (train_i, val_i) in enumerate(k_fold.split(X,y)):\n",
        "        print(len(train_i), len(val_i))\n",
        "        train_data = X[train_i]\n",
        "        val_data = y[val_i]\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "        lr = config_manager.config.lr\n",
        "        num_epochs = config_manager.config.num_epochs\n",
        "        batch_size = config_manager.config.batch_size\n",
        "        num_classes = config_manager.config.num_classes\n",
        "        weight_decay = config_manager.config.weight_decay\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        model = create_model(model_name)\n",
        "\n",
        "        loss_history, train_accuracy, val_accuracy, best_accuracy = trainer(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            num_epochs=num_epochs,\n",
        "            lr=lr,\n",
        "            batch_size=batch_size,\n",
        "            k_fold=k_id,\n",
        "            weight_decay=0.01,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # avg_accuracy = torch.mean(fold_accuracies)\n",
        "        # std_accuracy = torch.std(fold_accuracies)\n",
        "\n",
        "        # general plan\n",
        "        # 1. save best accuracies\n",
        "        # 2. compare with different models\n",
        "        # 3. train on full dataset with best performing model\n",
        "        # 4. make inference\n",
        ""
      ],
      "metadata": {
        "id": "rPK52nOff7-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvzBs1Xqf8Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foCtPMHheDQ3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config pull.rebase false\n",
        "!git pull\n",
        "# !git config --global user.email \"tomhyhan@gmail.com\"\n",
        "# !git config --global user.name username\n",
        "# !git add .\n",
        "# !git status\n",
        "# !git commit -m \"Updated Colab notebook\"\n",
        "# !git push https://{token}@github.com/{username}/{repo_name}.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVgELpYOexIv",
        "outputId": "0111a47c-a16f-4e29-d886-30356d478997"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 2.23 KiB | 2.23 MiB/s, done.\n",
            "From https://github.com/tomhyhan/noodles\n",
            "   0ec2d46..702e7c6  main       -> origin/main\n",
            "Updating 0ec2d46..702e7c6\n",
            "Fast-forward\n",
            " pasta_classification.ipynb | 257 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--------------\u001b[m\n",
            " 1 file changed, 201 insertions(+), 56 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aE18mn9Ge00W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}