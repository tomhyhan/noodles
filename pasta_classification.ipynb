{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOTrHp8K2sQaQtVWyZ/4d+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09f8123693dc4a6b9536e05bb36678b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f906471aaea140b0bc48f7b97daac7f4",
              "IPY_MODEL_98f48c196f074158811f9102156d55f6",
              "IPY_MODEL_283f306bbd6149a0a844930a9e29efb5"
            ],
            "layout": "IPY_MODEL_3923e16b0646457fbdb3ee1edba7ae82"
          }
        },
        "f906471aaea140b0bc48f7b97daac7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18277922a1f441c6ac6a0ea432d4c7f4",
            "placeholder": "​",
            "style": "IPY_MODEL_527d7c996cff49ec82c3df50eccbee13",
            "value": "Epoch 4/6:  12%"
          }
        },
        "98f48c196f074158811f9102156d55f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c681a3aa28044488aa9de25d762a91c8",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ce4cc0e0cc64134a1a1cdae3b407b2d",
            "value": 18
          }
        },
        "283f306bbd6149a0a844930a9e29efb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5290a6878674e828d22f1403eb7d66e",
            "placeholder": "​",
            "style": "IPY_MODEL_dd2607781c3542989e498c64826524f0",
            "value": " 18/150 [00:20&lt;02:24,  1.09s/it]"
          }
        },
        "3923e16b0646457fbdb3ee1edba7ae82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18277922a1f441c6ac6a0ea432d4c7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527d7c996cff49ec82c3df50eccbee13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c681a3aa28044488aa9de25d762a91c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce4cc0e0cc64134a1a1cdae3b407b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5290a6878674e828d22f1403eb7d66e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2607781c3542989e498c64826524f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomhyhan/noodles/blob/main/pasta_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "koRTiaedWIZg",
        "outputId": "b3584092-d95d-483d-c496-cf214fc912f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "token = userdata.get('token')\n",
        "username = userdata.get('username')\n",
        "repo_name = \"noodles\""
      ],
      "metadata": {
        "id": "AoEzSbksdZc_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/tomhyhan/{repo_name}.git\n",
        "\n",
        "if os.getcwd() != f\"/content/{repo_name}\":\n",
        "    %cd {repo_name}\n",
        "!git pull\n",
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp5GmDHYdx-f",
        "outputId": "16c9dac3-86fa-4afe-cb67-761778d06297"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'noodles'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 218 (delta 118), reused 144 (delta 64), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (218/218), 1.15 MiB | 13.11 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Already up to date.\n",
            "/content/noodles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "e2XfxhmmC5YR",
        "outputId": "82382501-159c-44d2-dc4a-05861e466d32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"noodles\"\n",
        "\n",
        "GOOGLE_DRIVE_PATH = os.path.join(\"..\", \"drive\", \"My Drive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n"
      ],
      "metadata": {
        "id": "XCcX3Z1YC98_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.utils import test_colab\n",
        "test_colab()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VNUEnJld36I",
        "outputId": "17d17967-4786-4e4d-d189-99cec619946f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Colab! from Noodles ha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG5zmBhQiSRI",
        "outputId": "2c4d7305-fa8d-450e-8aee-daf6722a0357"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (11.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "\n",
        "from config.config_manager import ConfigManager\n",
        "from collections import Counter\n",
        "from model.data_model import PastaData, create_train_transforms, create_test_transforms\n",
        "from model.train import trainer, create_model\n",
        "from model.utils import reset_seed, save_model\n",
        "from model.data import CLASS_ENCODER, create_csv\n",
        "from model.viz import class_imbalance, draw_loss, draw_train_val_accuracy"
      ],
      "metadata": {
        "id": "hGm4lDMygOyt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_manager = ConfigManager(\"./config/config.yml\")\n",
        "\n",
        "SEED = config_manager.config.seed"
      ],
      "metadata": {
        "id": "8duPbwRyiqLr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seed(SEED)"
      ],
      "metadata": {
        "id": "17_od-fOiIeZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = os.path.join(GOOGLE_DRIVE_PATH, \"images\")\n",
        "csv_file_path = os.path.join(GOOGLE_DRIVE_PATH, \"pasta_data.csv\")\n",
        "\n",
        "if not os.path.exists(csv_file_path):\n",
        "    create_csv(image_path, csv_file_path)"
      ],
      "metadata": {
        "id": "NMbIY34zDPb_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(os.path.join(GOOGLE_DRIVE_PATH, \"./pasta_data.csv\"))\n",
        "image_paths, labels = data[\"img_path\"], data[\"label\"]\n",
        "\n",
        "X, test_data, y, test_label = train_test_split(image_paths.values, labels.values, train_size=0.9, random_state=SEED, shuffle=True, stratify=labels)"
      ],
      "metadata": {
        "id": "1IOZHmWAf7pA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_fold = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
        "models = ['efficientnetv2' ]\n",
        "\n",
        "# N=100\n",
        "# perm_indices = np.random.permutation(N)\n",
        "# X = X[perm_indices]\n",
        "# y = y[perm_indices]\n",
        "\n",
        "for model_name in models:\n",
        "    current_model_accuracies = []\n",
        "    for k_id, (train_i, val_i) in enumerate(k_fold.split(X,y)):\n",
        "        if k_id in [0,1] and model_name == 'maxvit':\n",
        "            continue\n",
        "        print(len(train_i), len(val_i))\n",
        "        train_set = X[train_i]\n",
        "        train_label_set = y[train_i]\n",
        "\n",
        "        val_set = X[val_i]\n",
        "        val_label_set = y[val_i]\n",
        "\n",
        "        model_config = config_manager.config[model_name]\n",
        "        lr = config_manager.config.lr\n",
        "        num_epochs = config_manager.config.num_epochs\n",
        "        num_classes = config_manager.config.num_classes\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        train_transform = create_train_transforms()\n",
        "        test_transform = create_test_transforms()\n",
        "\n",
        "        train_data = PastaData(train_set, train_label_set, transform_list=train_transform)\n",
        "        train_data_accuracy = PastaData(train_set, train_label_set, transform_list=test_transform)\n",
        "        val_data = PastaData(val_set, val_label_set, transform_list=test_transform)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=model_config.batch_size, shuffle=False, drop_last=True)\n",
        "        train_loader_accuracy = DataLoader(train_data_accuracy, batch_size=model_config.batch_size, shuffle=False, drop_last=True)\n",
        "        val_loader = DataLoader(val_data, batch_size=model_config.batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "        model = create_model(model_name, num_classes)\n",
        "        model.to(device)\n",
        "\n",
        "        result_dir = os.path.join(GOOGLE_DRIVE_PATH, model_config.output_dir)\n",
        "        os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "        out_file = os.path.join(result_dir, f\"{model_name}_k_fold_{k_id}.pt\")\n",
        "\n",
        "        resume = False\n",
        "        if os.path.exists(out_file):\n",
        "            print(f\"=== {out_file} exist! ===\")\n",
        "            resume = True\n",
        "\n",
        "        #  need to make dataframe from images\n",
        "        loss_history, train_accuracy_history, \\\n",
        "        val_accuracy_history, best_accuracy, model, optimizer, scaler, end_epoch = trainer(\n",
        "            model,\n",
        "            train_loader,\n",
        "            train_loader_accuracy,\n",
        "            val_loader,\n",
        "            num_epochs=num_epochs,\n",
        "            lr=lr,\n",
        "            model_config=model_config,\n",
        "            device=device,\n",
        "            resume=resume,\n",
        "            out_file=out_file,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "\n",
        "        current_model_accuracies.append(best_accuracy)\n",
        "        print(f\"End of Training for {model_name} Model {k_id}-fold\")\n",
        "        print(f\"best accuracy: {best_accuracy}\")\n",
        "\n",
        "        save_model(model, optimizer, scaler, end_epoch, out_file, best_accuracy)\n",
        "        # torch.save(best_params, os.path.join(result_dir, f\"{model_name}_k_fold_{k_id}.pt\"))\n",
        "        draw_loss(loss_history)\n",
        "        draw_train_val_accuracy(train_accuracy_history, val_accuracy_history)\n",
        "\n",
        "\n",
        "    print(\"current_model_accuracies\", current_model_accuracies)\n",
        "\n",
        "\n",
        "        # avg_accuracy = torch.mean(fold_accuracies)\n",
        "        # std_accuracy = torch.std(fold_accuracies)\n",
        "\n",
        "        # general plan\n",
        "        # 1. save best accuracies\n",
        "        # 2. compare with different models\n",
        "        # 3. train on full dataset with best performing model\n",
        "        # 4. make inference\n"
      ],
      "metadata": {
        "id": "rPK52nOff7-g",
        "outputId": "746daffa-5dd4-4799-fde0-b3cd487ca8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "09f8123693dc4a6b9536e05bb36678b1",
            "f906471aaea140b0bc48f7b97daac7f4",
            "98f48c196f074158811f9102156d55f6",
            "283f306bbd6149a0a844930a9e29efb5",
            "3923e16b0646457fbdb3ee1edba7ae82",
            "18277922a1f441c6ac6a0ea432d4c7f4",
            "527d7c996cff49ec82c3df50eccbee13",
            "c681a3aa28044488aa9de25d762a91c8",
            "3ce4cc0e0cc64134a1a1cdae3b407b2d",
            "c5290a6878674e828d22f1403eb7d66e",
            "dd2607781c3542989e498c64826524f0"
          ]
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5032 1259\n",
            "=== ../drive/My Drive/noodles/./efficientnetv2/efficientnetv2_k_fold_0.pt exist! ===\n",
            "Resume Training from previous check point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/noodles/model/utils.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(out_file, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 4/6:   0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f8123693dc4a6b9536e05bb36678b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-43461f48a75b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#  need to make dataframe from images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         val_accuracy_history, best_accuracy, model, optimizer, scaler, end_epoch = trainer(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/noodles/model/train.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(model, train_batch, train_batch_accuracy, val_batch, num_epochs, lr, model_config, device, early_stop, resume, out_file, num_classes)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mcurrent_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "V0FnJZ3EUXim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "npUClvJFUYnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n",
        "!git config --global user.email \"tomhyhan@gmail.com\"\n",
        "!git config --global user.name username\n",
        "!git add .\n",
        "!git status\n",
        "!git commit -m \"updated trainer\"\n",
        "!git push https://{token}@github.com/{username}/{repo_name}.git"
      ],
      "metadata": {
        "id": "DVgELpYOexIv",
        "outputId": "1ac2e5c3-894a-4450-b501-ee05821524cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/tomhyhan/noodles\n",
            "   797d7f7..bb10011  main       -> origin/main\n",
            "Already up to date.\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "  (commit or discard the untracked or modified content in submodules)\n",
            "\t\u001b[31mmodified:   noodles\u001b[m (modified content)\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "  (commit or discard the untracked or modified content in submodules)\n",
            "\t\u001b[31mmodified:   noodles\u001b[m (modified content)\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aE18mn9Ge00W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}